{
  "system_prompt": "You are a senior robotic RL reward engineer.\nDesign reward logic that is goal-aligned and hard to game.\nReturn practical implementation-ready output.",
  "user_prompt": "You are helping design a reward specification for a robotic RL manipulation task: OGBench + QAM, \"double-cube-play-task2.\" The agent must place two cubes into their designated goal positions. We want a reward that improves learning (offline+online and online-only) but avoids reward hacking (threshold gaming, jitter loops, stage skipping, shaping exploits).\nWe prefer reward specs that are: (i) goal-aligned, (ii) hard to exploit, (iii) easy to instrument with diagnostics, and (iv) testable with invariants.\nWhen you propose terms, always include: exact definitions, state variables required, expected ranges, and the main failure modes each term might introduce.\n\nPrompt 1 \u2014 Task decomposition into stages (two cubes, two goals)\n\nGoal: define stages that are robust in a multi-object setting (avoid \"progress cancels out\" issues).\n\nDecompose \"double-cube-play-task2\" into a minimal set of stages that are (a) necessary for success, (b) observable from OGBench/QAM signals, and (c) hard to spoof.\n\nRequirements:\n- Must handle two cubes without assuming a fixed order, but you may propose an \"active cube\" selection rule if needed.\n- Each stage must have entry/exit conditions with explicit thresholds and hysteresis if relevant.\n- Include a \"stage completion\" event definition that fires once to prevent farming.\n- For each stage, list \"most common exploit\" and \"anti-exploit guard.\"\n\nOutput format (STRICT JSON ONLY; no markdown, no prose before/after):\n{\n  \"task\": \"double-cube-play-task2\",\n  \"active_cube_rule\": \"string\",\n  \"stages\": [\n    {\n      \"id\": \"S0\",\n      \"signals\": [\"string\"],\n      \"entry\": \"string\",\n      \"exit\": \"string\",\n      \"h\": \"string\",\n      \"event\": \"string\",\n      \"exploit\": \"string\",\n      \"guard\": \"string\"\n    }\n  ]\n}\n\nRules:\n- Return valid JSON parseable by Python json.loads.\n- Do not wrap output in ```json fences.\n- Use stage IDs S0..Sk.\n- Include explicit numeric thresholds in entry/exit/h where possible.\n- Keep each string field concise (<= 220 characters).\n- Keep total output under 1200 characters.",
  "video_path": "/rlwrld3/home/hyeonbin/RL/qam/artifacts/double_demo.mp4",
  "raw_response": "```json\n{\n  \"task\": \"double-cube-play-task2\",\n  \"active_cube_rule\": \"Select unplaced cube closest to gripper. If one placed, select the other. If both placed, none. (A_placed/B_placed are sticky flags).\",\n  \"stages\": [\n    {\n      \"id\": \"S0\",\n      \"signals\": [\"gripper_pos\", \"cube_A_pos\", \"cube_B_pos\", \"gripper_open_state\"],\n      \"entry\": \"!(A_placed || B_placed) && !A_grasped && !B_grasped\",\n      \"exit\": \"(A_grasped && !A_placed) || (B_grasped && !B_placed)\",\n      \"h\": \"Exit for 5 steps. A_grasped: dist(gripper,A)<0.03 & gripper_open<0.1. B_grasped similar.\",\n      \"event\": \"First cube grasped.\",\n      \"exploit\": \"Hover near cube without grasping; grasp and immediately release.\",\n      \"guard\": \"Hysteresis on grasp. 'placed_flag' is sticky.\"\n    },\n    {\n      \"id\": \"S1\",\n      \"signals\": [\"gripper_pos\", \"cube_A_pos\", \"cube_B_pos\", \"goal_A_pos\", \"goal_B_pos\", \"gripper_open_state\"],\n      \"entry\": \"(A_",
  "parsed_json": null
}